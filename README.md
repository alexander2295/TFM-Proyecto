ğŸ“Œ TFM-Proyecto
Proyecto de anÃ¡lisis de datos de YouTube con extracciÃ³n, procesamiento y almacenamiento en MySQL utilizando Kafka.

ğŸ“– Ãndice
1. ğŸ”§ Requisitos previos
2. ğŸ“‚ Estructura del proyecto
3. âš™ï¸ InstalaciÃ³n
4. ğŸš€ EjecuciÃ³n
5. ğŸ“¡ ConfiguraciÃ³n de Kafka
6. ğŸ’¾ Base de Datos MySQL
7. ğŸ“¢ Pipeline de Datos

ğŸ”§ Requisitos previos
Antes de empezar, asegÃºrate de tener instalado:
â€¢	âœ… Python 3.10 o superior
â€¢	âœ… Docker y Docker Compose (para ejecutar Kafka)
â€¢	âœ… MySQL Server
â€¢	âœ… Git (para clonar el repositorio)



ğŸ“‚ Estructura del proyecto
TFM-Proyecto/
â”‚â”€â”€ airflow/                # ConfiguraciÃ³n de Apache Airflow
â”‚â”€â”€ data/                   # Datos procesados
â”‚â”€â”€ prometheus/             # ConfiguraciÃ³n de Prometheus (Opcional)
â”‚â”€â”€ reportes/               # Reportes y anÃ¡lisis de datos
â”‚â”€â”€ scripts1/               # CÃ³digo de los reproductores y consumidores
â”‚   â”œâ”€â”€ reproductores/      # Scripts para extraer datos de YouTube
â”‚   â”‚   â”œâ”€â”€ reproductor1.py
â”‚   â”‚   â”œâ”€â”€ reproductor2.py
â”‚   â”‚   â”œâ”€â”€ reproductor3.py
â”‚   â”œâ”€â”€ consumidor/         # Scripts para procesar y almacenar datos en MySQL
â”‚   â”‚   â”œâ”€â”€ consumidor1.py
â”‚   â”‚   â”œâ”€â”€ consumidor2.py
â”‚   â”‚   â”œâ”€â”€ consumidor3.py
â”‚â”€â”€ docker-compose.yml      # ConfiguraciÃ³n de Kafka y MySQL en Docker
â”‚â”€â”€ pipeline_data.py        # Pipeline de datos (ejecuciÃ³n automÃ¡tica)
â”‚â”€â”€ requirements.txt        # Dependencias del proyecto
â”‚â”€â”€ README.md               # DocumentaciÃ³n del proyecto
â”‚â”€â”€ .gitignore              # Archivos a ignorar en GitHub

âš™ï¸ InstalaciÃ³n
1ï¸âƒ£ Clonar el repositorio
```sh
git clone https://github.com/alexander2295/TFM-Proyecto.git
cd TFM-Proyecto
```
2ï¸âƒ£ Crear y activar un entorno virtual
```sh
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate  # Windows
```
3ï¸âƒ£ Instalar dependencias
```sh
pip install -r requirements.txt
```
ğŸš€ EjecuciÃ³n
1ï¸âƒ£ **Iniciar Kafka y MySQL con Docker**
```sh
docker-compose up -d
```
2ï¸âƒ£ **Ejecutar los scripts de extracciÃ³n de datos**
```sh
python scripts1/reproductores/reproductor1.py
```
3ï¸âƒ£ **Ejecutar el consumidor para procesar y almacenar los datos**
```sh
python scripts1/consumidor/consumidor1.py
```
4ï¸âƒ£ **Ejecutar el pipeline de datos**
```sh
python pipeline_data.py
```

ğŸ“¡ ConfiguraciÃ³n de Kafka
Si necesitas crear un **tÃ³pico en Kafka**, usa:
```sh
docker exec -it kafka kafka-topics.sh --create --topic youtube_data --bootstrap-server kafka:9092 --partitions 1 --replication-factor 1
```
Para listar tÃ³picos:
```sh
docker exec -it kafka kafka-topics.sh --list --bootstrap-server kafka:9092
ğŸ“¡ ConfiguraciÃ³n de Kafka
Si necesitas crear un **tÃ³pico en Kafka**, usa:
```sh
docker exec -it kafka kafka-topics.sh --create --topic youtube_data --bootstrap-server kafka:9092 --partitions 1 --replication-factor 1
```
Para listar tÃ³picos:
```sh
docker exec -it kafka kafka-topics.sh --list --bootstrap-server kafka:9092
```
ğŸ’¾ Base de Datos MySQL
Si MySQL estÃ¡ en **Docker**, accede con:
```sh
docker exec -it mysql mysql -u root -p
```
Para crear la base de datos:
```sql
CREATE DATABASE youtube_data;
```
Para verificar tablas:
```sql
USE youtube_data;
SHOW TABLES;
```
ğŸ“¢ Pipeline de Datos
Para automatizar la ejecuciÃ³n de los scripts de extracciÃ³n y procesamiento de datos, ejecuta:
```sh
python pipeline_data.py


